import org.apache.spark.{SparkConf, SparkContext}

/**
  * Created by karen on 10/17/17.
  */


object PageRank {
  def main(args: Array[String]): Unit = {
    val conf=new SparkConf()
      .setAppName("PageRank")
      .setMaster("local")

    val sc=new SparkContext(conf)

    val lines=sc.textFile("web-Google.txt")
    val link_SrcDst=lines.map{line=>(line.split("\\s+")(0), line.split("\\s+")(1))}
      .distinct()
      .groupByKey() // group by FromNodeId
      .cache()

    var rank=link_SrcDst.mapValues(_=>1.0)  // set initial rank to be 1


    for (_<- 1 to 10) {

      val contribution=link_SrcDst
        .join(rank)
        /*
        * (sec_node_id, ((dst_node_id_1, dst_node_id_2, ...), rank))
        * example output:
          (729609,(CompactBuffer(330103, 521169, 782908, 449377),1))
          (28995,(CompactBuffer(425442, 527302, 226596, 153658, 514405, 751968, 516770, 556180, 58123, 225110, 470362, 912970, 403293, 771546, 490452),1))
          (892689,(CompactBuffer(51257, 345031, 630192, 827675),1))
          (393372,(CompactBuffer(704396, 832371, 352448, 584291, 132214, 478793),1))
          (581541,(CompactBuffer(751558, 346729, 861645, 395744),1))

        * */
        .values
        // ((dst_node_id_1, dst_node_id_2, ...), rank)

        .flatMap{ case (dst_node_list, r) =>
          val N=dst_node_list.size
          dst_node_list.map((_, r/N))

        }
      /*
      * (dst_node_id, rank(after adjusting))
      * example output:
        (782908,0.25)
        (449377,0.25)
        (425442,0.06666666666666667)
        (527302,0.06666666666666667)
        (226596,0.06666666666666667)
      *
      *
      *
      * */

      rank=contribution.reduceByKey(_+_).mapValues(0.15+0.85*_)
      /*
      * example output:
      * (dst_node_id, rank)
      *
        (729609,0.42388888888888887)
        (28995,2.281097374847375)
        (892689,1.0)
        (393372,0.3280952380952381)
        (581541,0.36587301587301585)
        (781047,0.9766498656758954)
        (617493,0.919047619047619)
        (432234,0.3972727272727272)
        (899514,1.49581481018981)
        (389625,0.7922222222222222)
        ...
        (729609,0.8786633019758018)
        (28995,2.1453909532228557)
        (892689,1.0)
        (393372,0.3266803236446093)
        (581541,0.44560758234270137)
        (781047,1.068633964033691)
        (617493,1.171349206349206)
        (432234,0.38383780991735533)
        (899514,1.2590019809735717)
        (389625,0.6011663580246913)
        ...
        ...
        ...
        (729609,0.8578860411271404)
        (28995,2.09870142080126)
        (892689,1.0)
        (393372,0.2473017205700101)
        (581541,0.34613408232118553)
        (781047,0.7828949690237691)
        (617493,0.9941287194702751)
        (432234,0.2478504624216405)
        (899514,0.8358664353255562)
        (389625,0.34375158956405194)
        ...
        (729609,0.8578860411271404)
        (28995,2.09870142080126)
        (892689,1.0)
        (393372,0.2473017205700101)
        (581541,0.34613408232118553)
        (781047,0.7828949690237691)
        (617493,0.9941287194702751)
        (432234,0.2478504624216405)
        (899514,0.8358664353255562)
        (389625,0.34375158956405194)
        ...
        (729609,0.8543190823982211)
        (28995,2.094639358570839)
        (892689,1.0)
        (393372,0.24565322061359374)
        (581541,0.3428111242414721)
        (781047,0.7650315495264144)
        (617493,0.989168808299153)
        (432234,0.24623547490559122)
        (899514,0.8239340977655305)
        (389625,0.3418026031664906)

      * */
      // therefore after 10 iterations, rank is close to converging.

    }

    val output=rank.collect()
    output.take(5).foreach(x => println(x._1 + " has rank: " + x._2 + "."))

  }

}
